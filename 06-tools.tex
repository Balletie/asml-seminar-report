\documentclass[multi,crop=false,class=article]{standalone}

\begin{document}
\section{Tools and Libraries}
\label{sec:tools}
The previous sections have shown that active automata learning is a currently
studied computational learning process. However, as \cref{sec:variants} has
shown, there are some challenges in using active automata learning in a
practical setting. To overcome these challenges as well as to promote active
automata learning in practice, tools and libraries have been created. This
section will give a brief overview of a couple of tools and libraries. This
selection is based on the importance, availability and the amount of researches
that have used these tools and libraries. First, the libraries Libalf and
Learnlib will be discussed. These libraries provide various active automata
learning algorithms and optimizations. After that, the tool Tomte is discussed,
which automatically generates abstractions for automata in order to apply active
automata learning on them.


\subsection{Libalf}
\label{sssec:libalf}
Libalf\footnote{No support available, but can be downloaded from 
\url{http://libalf.informatik.rwth-aachen.de}} is a library for learning and 
manipulating formal languages. It has both active and passive automata learning 
algorithms. The name is short for Automata Learning Framework. In this article, 
only the active part is covered.

The library consists of a core library and two additional libraries, 
liblangen (random regular language generator) and AMoRE++ (automata library).

The core consists of the learning algorithms and the knowledgebase. The 
knowledgebase stores language information and collects the different queries 
that are used for that language. This storage makes it possible to switch 
learning algorithms or to use multiple learning algorithms during the learning 
process. Therefore, Libalf is suitable for experimenting with different kinds 
of learning algorithms to see how they affect the learning process. 

\begin{figure}[!ht]
	\includegraphics[width=\textwidth]{Tool_images/libalf_demo_interface.png}
	\caption{Application interface of Libalf}
	\label{fig:libalf_interface}
\end{figure}

Besides using Libalf as a library, a demo application is also available. In 
this application, each learning configuration is stored in a scenario. Each 
scenario contains the learning algorithm, filters, connectivity (server or 
local) and the implementation of the Teacher. The Teacher can either be 
based on a supplied model (DFA or regular expression) or the role of the 
Teacher is filled in by the user. 

When a scenario is started, there is an option to let the algorithm run 
step by step. This means that the user can go through the learning algorithms 
in a step-wise manner, to see how it handles the membership queries and the 
counterexamples. 

The active learning algorithms that Libalf offers are listed below:

\begin{itemize}
	\item $L^*$ (see \cref{sec:an-algor-learn})
	\item Rivest \& Schapnire's (see \cref{sec:rivest-schap-count})
	\item $NL^*$ \cite{Bollig2009}
	\item Kearns \& Vazirani's (see \cref{sec:classification-trees})
\end{itemize}

Besides the algorithms and the knowledgebase, Libalf has filters for reducing 
the amount of queries asked to the Teacher. These filters use domain specific 
knowledge. If a query can already be answered by this filter, it is not passed 
to the Teacher, thus reducing the queries asked to the Teacher. A filter can 
also be composed of multiple filters by using logical connectors ($\land$, 
$\lor$ and $\lnot$).

Libalf also provides normalizers. A normalizer defines a domain specific 
equivalence relation (relation between equivalence queries) over all strings 
and only stores information of one representative of that relation. This 
reduces the amount of memory needed and could also reduce the amount of 
equivalence queries.

More information on Libalf is published in \cite{Bollig2010}.

\subsection{Learnlib}
\label{ssec:learnlib}

Learnlib\footnote{Supported through bug fixes and available from
\url{https://github.com/LearnLib/learnlib}} is a library that implements various
active learning algorithms as well as different configurations for learning
automata. It has been in development since 2009 \cite{Raffelt2009} and as of
2015, there has been a total overhaul of the library \cite{Isberner2015b}. To
avoid confusion, the old version was renamed to JLearn.

The current version of this library consists out of two parts: Automatalib and
Learnlib.

\begin{figure}[!ht]
	\includegraphics[width=\textwidth]{Tool_images/automatalib_architecture.png}
	\caption{Architecture of Automatalib, source is from \cite{Isberner2015b}}
	\label{fig:automatalib_arch}
\end{figure}

\paragraph{Automatalib} Automatalib is an independent library that contains
abstract automata representations, automata data structures and algorithms (see
figure \ref{fig:automatalib_arch}). The
abstract automata representations make the library flexible because all data
structures and algorithms depend on these representations. This makes it easy
to add third party implementations of automata such as the BRICS library
\cite{Alur2005}. Automatalib includes minimalization algorithms and equivalence
testing algorithms based on Hopcroft and Karp's near-linear equivalence
algorithm \cite{Hopcroft1971} or the W-Method (\cref{sec:chow}) for
black-box testing.

\begin{figure}[!ht]
	\includegraphics[width=\textwidth]{Tool_images/learnlib_architecture.png}
	\caption{Architecture of Learnlib}
	\label{fig:learnlib_arch}
\end{figure}

\paragraph{Learnlib} Learnlib is a library that provides learning algorithms and
infrastructure for automata learning. The learning algorithms consist of a base
algorithm. This algorithm can be altered by replacing the counterexample
analysis with other methods. All the official supported base algorithms with
their alternative counterexample analysis are listed below:

\begin{itemize}
	\item $L^*$ (see \cref{sec:an-algor-learn})
	\begin{itemize}
		\item Maler \& Pnueli's \cite{Maler1995}
		\item Rivest \& Schapnire's (see \cref{sec:rivest-schap-count})
		\item Shahbaz's \cite{Shahbaz2009}
		\item Suffix1by1 \cite{Irfan2010}
	\end{itemize}
	\item Obversation Pack (see \cref{sec:ttt})
	\item Kearns \& Vazirani's (see \cref{sec:classification-trees})
	\item DHC \cite{Merten2012}
	\item TTT (see \cref{sec:ttt})
	\item $NL^*$ \cite{Bollig2009}
\end{itemize}

All the algorithms work with both DFAs and Mealy machines (see 
\cref{sec:learn-mealy-mach}), except for DHC\cite{Merten2012} and
$NL^*$\cite{Bollig2009}.

For finding the counterexamples, Learnlib uses Automatalib as well as other
methods such as randomized tests. More methods can be found in
\cite[p. 490]{Isberner2015b}.

Learnlib also offers filters that pre-process the queries of the learning
algorithm. An example is the reduction of the amount of queries (see 
\cref{sec:noreset}). Other examples are a mechanism for reducing the amount of
resets  and a parallelization component that uses multiple Teachers and
parallel execution of membership queries\cite{Henrix2015,Howar2012}.


Besides the library, there is also an application called Learnlib 
Studio\footnote{Available from 
\url{http://ls5-www.cs.tu-dortmund.de/projects/learnlib/download.php}}. 
This application is based on the older version, JLearn, but it offers a 
graphical interface. See figure \ref{fig:learnlib_studio}. 

	\begin{figure}[H]
		\includegraphics[width=\textwidth]{Tool_images/learnlib_studio_interface.png}
		\caption{Graphical interface of Learnlib Studio}
		\label{fig:learnlib_studio}
	\end{figure}

The interface makes it possible to use the different building blocks of 
JLearn (similar to Learnlib) in a graph structure. These building blocks 
consist of the different learning algorithms, oracles, statistics and more. 


\subsection{Tomte}
\label{ssec:tomte}

Tomte\footnote{Named after a character from the book: The Wonderful Adventures 
of Nile}\footnote{In active development and available from
\url{http://tomte.cs.ru.nl/Tomte-0-4}} is a command-line tool that 
automatically makes abstractions for automata learning.  It is essentially a 
translator between the SUL and the Learner. This makes 
tools such as Learnlib easier to use, since the user does not have to make the 
mapping manually.

\begin{figure}[!h]
	\includegraphics[width=\textwidth]{Tool_images/tomte_network.png}
	\caption{Architecture of Tomte}
	\label{fig:tomte_arch_interaction}
\end{figure}

The Abstractor, Lookahead Oracle and Determinizer together form Tomte. The
other two parts are not part of Tomte, but it comes with Learnlib for making
the Learner. The makers also have a tool\footnote{SUL tool available from
\url{http://tomte.cs.ru.nl/Sut-0-4/Description}} available for creating the SUL
since they must be modeled after a register automaton\cite{Aarts2015}
(which is an extension of a Mealy machine).

\paragraph{Determinizer} The Determinizer elimates the nondeterministic
behavior caused by the SUL. Since tools like Learnlib can only analyze
deterministic behavior, it needs to converted. The theory behind it is
explained in \cite[p. 172]{Aarts2015}.

\paragraph{Lookahead Oracle} This oracle is used to annotate events of the SUL
with information about the impact on the future behavior of the SUL. This way,
the Lookahead Oracle acts as a cache for the Abstractor. The theory and
implementation of this oracle is found in \cite[p. 170]{Aarts2014} and
\cite[p. 105]{Tomte2014}.

\paragraph{Abstractor} The Abstractor is the component that creates the mapping
between the SUL and the Learner. The idea behind the Abstractor is to make the
model that needs to be learned by the Learner smaller than the SUL. This is
needed, because a SUL typically has parameter values that make the alphabet
large.

The Abstractor uses a concrete input set $\Sigma$ and a concrete
output set $\Lambda$ used by the SUL. Then, with the help of
counterexample-guided abstraction refinement\cite[p. 104]{Tomte2014} an
abstracted input set $X$ and output set $Y$ is created. Those abstracted sets
then represent a smaller model of the SUL. In order to make it scalable, this
component also tries to reduce the length of the counterexample by removing
loops and single transitions \cite{Koopman2014}. The complete theory is found
in \cite{Tomte2014}.

\paragraph{Interaction between the modules} The exchange of messages between
all the modules is as follows (see numbering in figure
\ref{fig:tomte_arch_interaction}. For more information about this process see
\cite{Aarts2015,Tomte2014}.

\begin{enumerate}
	\item The Learner sends an abstract query $x \in X$ to the Abstractor.
	\item The Abstractor receives an abstract query, selects a concrete input
	symbol $i \in \Sigma$ and sends it as a query to the Lookahead
	Oracle. If no input symbol $i$ exists, return the symbol $\perp$ to the
	Learner.
	\item The Lookahead Oracle checks if $i$ is cached. If not, then $i$ is send
	to the Determinizer. Otherwise, go to step 7.
	\item The Determinizer transforms the input back to the original behavior of
	the Teacher.
	\item The Determinizer receives the output from the Teacher and transforms
	this into deterministic behavior.
	\item The Determinizer sends concrete symbol $o \in \Lambda$ to the
	Lookahead Oracle which caches the pair $\{i,o\}$.
	\item The Lookahead Oracle sends $o$ together with the annotated information
	that came after the sequence of queries between the last reset query and
	$i$.
	\item Abstractor receives a concrete answer $o$ and the annotated
	information. It uses the annotated information to determine updates to the
	state variables of the Learner. It sends those updates and other
	information to the Learner as an abstract answer $y \in Y$.
\end{enumerate}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
