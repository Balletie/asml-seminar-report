\documentclass[multi,crop=false,class=article]{standalone}

\begin{document}
\section{Applications}
\label{sec:applications}

\subsection{Tools}
\label{ssec:tools}

In order to encourage the use of active automata learning in a practical 
setting, tools have to be created. This section will give a brief overview some 
of the different tools that are available. Tools that are not considered are
are tools that are only used in automata verification, tools that are not 
available like RALT \cite{Shahbaz:2014:ATB:2858086.2858089} and tools that are 
not used a lot like AIDE \cite{Cicala2016} 

\subsubsection{Learnlib}
\label{sssec:learnlib}

Learnlib  \footnote{In active development and available from 
https://github.com/LearnLib } is a library that implements various active 
learning algorithms as well as different configurations for learning 
automata's. It is in development since 2009 \cite{Raffelt2009} and as of 2015, 
there has been a 
total overhaul of the tool \cite{Isberner2015}. To avoid confusion, the old 
version was renamed 
to JLearn. 

\todo{Image of architecture of Learnlib }
The current version exists out of two parts: Automatalib and Learnlib.

\todo{Image of architecture of Automatalib }

\paragraph{Automatalib} An independent library that contains: an abstract 
automata representations, automata data structures and algorithms. The abstract 
automata representations makes the library flexible because all data structures
and algorithms depends on those representations. This makes it easy to add 
third party like the BRICS library \cite{Alur:2005:SIS:1047659.1040314}. The 
algorithms that are included are: minimalization and equivalence testing based 
on Hopcroft and Karp's \cite{hopcroft1971linear} or the W-Method for black-box 
testing. 

\paragraph{Learnlib} A library that provides learning algorithms and 
infrastructure for automata learning. The learning algorithms consists of a 
'base algorithm' whereby the counterexample analysis can be exchanged with 
other methods. All the different base algorithms with the examples of variants 
that are officially supported are listed below:

\begin{itemize}
	\item L* (base)
	\begin{itemize}
		\item Maler \& Pnueli's
		\item Rivest \& Schapnire's
		\item Shahbaz's
		\item Suffix1by1
	\end{itemize}
	\item Obversation Pack (base)
	\item Kearns \& Vazirani's (base)
	\item DHC (base)
	\item TTT (base)
	\item NL*
\end{itemize}

All the algorithms come with both DFA and Mealy versions, expect for DHC and NL*.

For finding the counterexamples, Learnlib uses Automatalib as well as other 
methods like randomized tests. More methods can be found in \cite{Isberner2015}.

Learlib also offers filters for reducing the amount of queries such as 
elimination of duplicate queries. %Is hier een theoriestuk over?
It also contains a parallellization component that can speed up the process by 
using multiple teachers and parallel execution of membership 
queries\cite{Henrix15}\cite{Howar2012}. 

\subsubsection{Libalf}
\label{sssec:libalf}
Libalf\footnote{Not in active development since 2011 but still available 
from http://libalf.informatik.rwth-aachen.de} is a library for learning and 
manipulating formal languages. It has both active and passive learning 
algorithms. For this paper, only the active part is covered.

\todo{Image of architecture of libalf }
The library consists of a core library as well as two additional libraries:liblangen(random regular language generator) and AMoRE++(
automata library that included DFA,NFA,Mealy and is extendable).

The core consists of the learning algorithms and the knowledgebase. The latter 
stores language information and collects the different queries that are used 
for that language. This storage makes it possible to switch learning algorithms 
or use multiple learning algorithms during the learning process. The active 
learning algorithms that it offers are listed below.

\begin{itemize}
	\item L*
	\item Rivest \& Schapnire's
	\item NL*
	\item Kearns \& Vazirani's
\end{itemize}

Besides the algorithms and the knowledgebase, it has filters for reducing the 
amount of queries asks to the teacher. These filters uses domain specific 
knowledge. %Is hier theorie over?
Also, it provides methods that uses domain specific relation for reducing the 
amount of storage needed. 

More information on Libalf is published in \cite{Bollig2010}.

\subsubsection{Tomte}
\label{sssec:tomte}
Tomte \footnote{In active development and available from 
http://tomte.cs.ru.nl/Tomte-0-4} is a tool that automatically makes 
abstractions for automata learning. Essentially, it a connector between the 
system under learning(SUL) and the learner. This makes using Learnlib and 
Libalf easier, since the user doesn't have to make the mapping.

\todo{Image of architecture of Tomte }

The Abstractor, Lookahead Oracle and the Determinizer together forms Tomte. The 
other two parts are not considered part
of Tomte but it comes with a supplied library (Learnlib) for making the learner.
The makers also have a tool \footnote{SUL Tool available from 
http://tomte.cs.ru.nl/Sut-0-4/Description} available for creating the SUL since 
they must be modeled after a register automata.
 
\paragraph{Determinizer}
This parts elimates the nondeterministic behaviour caused by the SUL. Since 
tools like Learnlib can only analyse deterministic behaviour, it needs to 
converted. The theory behind it, is explained in \cite{Aarts2015}.

\paragraph{Lookahead Oracle}
This oracle is used to annotate each output action of the SUL with values that 
has an impact on the future behaviour of the SUL. This makes it is possible to 
learn any deterministic register automaton. The theory and implementation of 
this oracle is found in \cite{Aarts2014} and \cite{tomte14}.

\paragraph{Abstractor}
The Abstractor is the component that creates the mapping between the SUL and 
the learner. The idea behind the mapper is to make an abstraction of the 
parameter values of the SUL but leaving the input/output symbols unchanged. It 
uses counterexample-guided abstraction refinement\cite{tomte14} for extending 
of the mapping. In order to make it scalable, this component also tries to 
reduce the length of the counterexample by removing loops and single 
transistion \cite{Koopman2014}. The complete theory is found in \cite{tomte14}.

\subsubsection{Performance comparisons}
\label{ssec:performance_compare}
This section gives an overview on what the perfomance is of each the tools 
listed. It uses the comparisons that are published in 
\cite{Aarts2014}\cite{Aarts2015} and 
the website of 
Learnlib.

\paragraph{Learnlib vs JLearn}

\todo{Image of comparison between Learnlib and JLearn] } 
%language of size ten and the automaton to be learned has 500 states
%(learnlib.de/features/jlearn-performance-comparison)
This comparion is between the old version of Learnlib (JLearn) and the new 
version. For this comparisons, the tools have to learn a randomly generated 
alphabet of a certain size which are implemented in Mealy machine of various 
state sizes.

X shows that for this comparison, the new version of Learnlib is 
significant faster with all algorithms than JLearn.

\paragraph{Learnlib vs Libalf}
\todo{Image of comparison between Learnlib and Liblaf }
%(learnlib.de/features/libalf-performance-comparison)
The second comparison is between the new version of Learnlib and Libalf.
The same setup is used as the previous one, however the tools have to learn a 
DFA instead.

This comparison shows that Learnlib performs a lot better than Libalf. 

\paragraph{Tomte vs Learnlib}
\todo{Image of comparison between Learnlib and Tomte }
The last comparison is between Tomte(with learnlib) and Learnlib alone. 
For this setup, a number of real world models are used. These includes: the 
Biometric Passport \cite{Aarts2010}, a login procedure and the session 
initiation protocol. The tools had to learn a register automata. This meant 
that support for learning register automata for Learnlib to be added. 
\footnote{Source code and publications can be found here 
https://github.com/LearnLib/raxml}

According to X, Tomte performs better than Learnlib and can learn more models 
than Learnlib. However, Learnlib can outperform Tomte if during testing a 
perfect equivalence oracle is available. This is shown and explained in 
\cite{Aarts2014}.



In conclusion, from the comparisons it is clear that there is a lot of 
improvement in the creation of the tools in recent years by using the new 
methods that are found by either testing the tools on practical applications or 
new advances in active automata learning.


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
