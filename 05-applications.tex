\documentclass[multi,crop=false,class=article]{standalone}
\onlyifstandalone{\input{common}}

\begin{document}
\section{Applications}
\label{sec:applications}

As the previous chapters have shown, active state machine learning is a well
studied theoretical learning technology. Slowly but surely activate state
machine learning is moving from a theoretical novelty to a real world applicable
technology, due to hardware advancements as well as the optimizations discussed
in chapter \cref{sec:improvements}.

This chapter serves to highlight some interesting and important practical
applications of active state machine learning. The goal is not to discuss
individual applications, rather several ``domains'' of application have been
identified. Before doing so, however, the bridge between theory and application
must be crossed.

\subsection{From theory to practice}
\label{ssec:theory-to-practice}

The learning algorithms discussed in the previous chapters all required an
(abstract, formal) input alphabet, an (abstract, formal) output alphabet,
membership queries and equivalence queries. In practice, it is in many cases
quite difficult to realize these requirements for a specific system under
learning\cite{Stefen11a}. This section discusses these challenges faced when
applying active state machine learning to real world scenarios.

\paragraph{Interaction with real world applications} Before active state machine
learning can be used in practice, a mapping has to be made from an abstract,
formal input alphabet to a concrete real world ``language'' understood by
reactive systems (it is evident that reactive systems are a requirement for
practical active state machine learning)\todo{begrippenlijst aanmaken met
definities?}. This mapping needs to result in a deterministic language for it to
work\cite{Steffen11a}. In the same way, the output of the system under learning
needs to be mapped back to an abstract language understood by the tool (see
section \cref{sec:tools} below).

Whilst such a mapping has different peculiarities per application, there is an
overlapping theme that applies to every mapping: it needs to be abstract enough
in terms of communication (leading to a useful model structure, see below) while
allowing for an automatic back and forth translation between the abstract and
the concrete languages\cite{Steffen11a}. An interesting fact is that it turns
out that the active state machine learning algorithm can be enhanced per
application using application-specific optimizations\cite{Hungar03}. For more
information on recent work focusing on these abstractions, see
\cite{Aarts10,Howar11,Jonsson11}.

Besides mapping input- and output alphabets, the gap between the abstract
learned model and the concrete application also has to be bridged: when an
abstract learned model is presented to the user, it has to be ``translated'' to
a representation of the system under learning. This is rather intuitive for
those applications that are designed explicitly for connectivity (such as web
services or communication protocols), because these are made to be invoked from
the outside. For other types of applications, this can be arbitrarily difficult.

Another obstacle to overcome is that of parameters used in real world
applications. Think, for example, about increasing sequence numbers in
communication protocols. This is still a huge challenge to
resolve\cite{Steffen11a}, and, for now, besides the creation of prototypical
solutions\cite{Aarts10,Shahbaz07,Howar10}, application-specific solutions have
to be applied.\cite{Steffen11a}.

The final hurdle is that of a ``reset''. Membership queries have to be
independent (see chapter \cref{sec:noreset}). In practice this often means that
applications have to be reset in between successive membership queries. This can
be achieved using homing sequences\cite{Rivest93} (discussed in chapter
\cref{sec:variants} or by simply restarting the application for each membership
query.

\paragraph{Membership queries} Membership queries are the most straightforward
to translate to real world applications: they can be realized via testing. An
important thing to note, however, is the amount of membership queries required.
Learning a real world application can easily require several thousand membership
queries\todo{Add citation}. This means that the time required to learn a model
can be greatly reduced either by speeding up membership queries (executing them
in parallel), or simply by reducing the number of membership queries required.
Chapter \cref{sec:improvements} has discussed several improvements to achieve
exactly that. Additionally, application-specific optimizations can be used to
further reduce the number of membership queries required.

\paragraph{Equivalence queries} In theoretical simulations, equivalence testing
is often easy because often the target system (in some cases even the model!) is
known. In practice, however, the system under test is usually a black box
system. This means that equivalence queries will have to be approximated,
typically using membership queries. These approximated membership queries are in
general not decidable without assuming any extra knowledge\cite{Steffen11a},
such as the number of states of the system under learning: it is impossible to
be certain that the system has been tested extensively enough.

An alternative to using membership queries to simulate equivalence queries, is
to use model-based testing methods\cite{Broy05, Tretmans11}. An example of
model-based testing is Chow's W-method\cite{Chow78} (discussed in chapter
\cref{sec:improvements}), which can be used if an upper bound on the number of
states in the system is known.\todo{Mention Wp-method\cite{Fujiwara91} and more
examples? Or refer to chapter \cref{sec:variants}}

\todo{Discuss first paragraph of page 33 in \cite{Steffen11a}?}

All the above problems might give the impression that active state machine
learning is not yet applicable to real world applications. While it is true that
practical application is not yet complete, great progress has been made and
great things have already been achieved. The next few highlights of real world
applications serve to illustrate these facts.

\subsection{Protocol Verification}
One commonly used application of active state machine learning is
protocol verification. This checks whether a protocol implementation follows
its formal description. This description is used to identify states and
allowed transitions. These transitions are then used to find out whether the
implementation's logic is according to the specification. The input alphabet
is defined as an abstract set of messages that relate to the messages the
protocol specification defines. Furthermore, an output alphabet is defined,
containing a set of abstractions of the possible messages the protocol can
output. Often, the output alphabet is concatenated with some special states,
like a reset state. Later on in this section, an example of such an extension
is given.

Sequences of input messages are then constructed and passed as to the
verification machine. If the machine's output matches the expected output, the
logic of the implementation is correct. However, if the expected output does
not match the actual output, there is some bug in the implementation of the
protocol that is being tested. The tests are performed as black box testing,
resulting in the need for approximation as explained in
\ref{sec:theory-to-practice}\todo{verify ref after Gerlof and Jente have decided
which overlapping section to use eventually}. One specific example of protocol
verification is given below. More examples applications can be found in
\cite{Aarts13,Cho10,Aarts10}.

\paragraph{TLS-protocol verification} For this specific protocol verification
application\cite{deRuiter15}, an improved version of the W-method as explained
in \todo{refer to Stefans section} is used. The improvement comes forth from
the fact that the TLS-protocol requires the output to be ``Connection closed''
at all times, once a connection is closed. By making use of this and thus
limiting the W-method to halt whenever the connection is closed, a great
reduction in the time needed to perform the implementation analysis is
achieved. Furthermore, especially since the W-method is a very costly one,
interrupting the trace generation as soon as the connection has been closed
reduces the number of membership queries significantly.
An aspect that has proven to be difficult in practice, namely that of
resetting the state of the machine after each iteration, is for this specific
application fairly easy. De Ruiter et al. defined an additional message, a
``reset''-message. This, when output, sets up a new client-server connection,
after which a new iteration can start.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
