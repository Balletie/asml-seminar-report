\documentclass[multi,tikz,crop=false,class=article]{standalone}

\onlyifstandalone{\input{common}}
\onlyifstandalone{\usepackage{mathtools}}
\onlyifstandalone{\usepackage{algpseudocode}}
\onlyifstandalone{\DeclareCaptionType{algorithm}}

\usetikzlibrary{automata,arrows}

\begin{document}
\section{Variants}
\label{sec:variants}
In the first few years following the introduction of the L* algorithm by
D. Angluin~\cite{Angluin1987}, L* learning was only a theoretical exploration.
The various improvements described in the previous chapter,
such as \textit{Classification Trees} \cref{sec:classification-trees} and
the \textit{TTT} algorithm \cref{sec:ttt}
made practical applications already more feasible.

In applying L* or improvements thereof to practical applications,
there were still some practical limitations and restrictions that had to
be addressed (Steffen 2011, Ch. 6~\cite{Steffen2011}).
Some of these issues can be summarized as follows:
\begin{itemize}
  \item Equivalence queries are generally undecidable for black boxes
  \item L* can only interact with regular languages, not with real systems
  \item The amount of required membership queries can grow very fast
  \item Membership queries might not be independent in practice,
        which imposes the requirement for a \textit{reset} function
  \item Not all systems might support a \textit{reset} function.
\end{itemize}

In order to address these limitations and restrictions,
several variants of the L* algorithm have been proposed,
each with the goal to solve such an issue.
In this chapter we will further elaborate on some of these issues
and the variants proposed to solve them.

\subsection{Approximating \textit{EQUIV (M)} queries with \textit{MEMBER (w)} queries}
The target machine on which the learning algorithm is applied is generally
a black box, since the main motive for using a learning algorithm is to
infer knowledge about some unknown system.
Therefore equivalence queries can generally only be answered by exhaustively
testing the inputs and outputs of a system.
However, exhaustively testing a black box is undecidably hard.

In order to solve this issue model-based testing techniques have been used,
such as \textit{Chow's W-method}~\cite{deRuiter2015, Chow1978} or the \textit{WP-method}.
These methods rely on approximating \textit{EQUIV (M)} queries by using
\textit{MEMBER (w)} queries.

To further research in this area,
the \textit{ZULU} challenge~\cite{Combe2010} was introduced.
The \textit{ZULU} challenge asked participants to find a DFA corresponding
to a certain system as accurately as possible, while imposing a restriction
on the number of \textit{MEMBER (w)} queries and disallowing \textit{EQUIV (M)}
queries completely.
\todo{add some more text and a fluid intro to Chow's method}

\subsubsection{Chow's W-method}
\label{sec:chow}
According to \cite{Vasilevskii1973}, the maximum number of test sequences needed
to converge to a correct approximation of the system under learning
is bounded by $n^{2} \times k^{m-n+1}$ when using Chow's W-method,
and the maximum length of these sequences is $n^{2} \times m \times k^{m-n+1}$,
where n is the number of states in the provided automaton, m is the number
of states in the correct automaton, and k is the size of the input alphabet.

By refining the test suites and the specification at the same time,
and by using a divide and conquer approach, the size of the test is
considerably reduced in comparison to defining the tests from
the final specification\cite{Ipate2007}.
This is especially beneficial because complex systems are usually
created in multiple iterations.
Unlike some other test selection methods the W-method does not require
that the number of states is exactly the same between
the implementation and protocol.
The W-method generates tests that guarantee correctness of an
implementation with a number of states below a certain upper bound.

The W-method generates input sequences that reach every state in the
diagram, checks all the transitions in the diagram and identifies all the
destination states and verifies them against their counterparts in
the implementation\cite{Ipate2007}.
To achieve this, the W-method constructs two sets of input sequences:
\begin{itemize}
  \item A state cover $S \subseteq \Sigma^{*}$ that reaches every state in the
    final state machine, including the empty sequence to reach the initial state.
  \item A characterization set $W \subseteq \Sigma^{*}$ that has different
    outputs for at least one sequence in $W$ for every pair of different states.
\end{itemize}

Given a specification P that can be modelled by an unknown finite state machine M,
the only information the algorithm needs is an estimate of the maximum number of
states of an unknown model for the specification.
Suppose $d = \text{estimated maximum number of states for P}
- \text{number of states in M}$.
Naturally, it follows that $d \geq 0$.
We also take $\Sigma \left[ n \right] = \Sigma^{n} \cup \dots \cup \lbrace \epsilon \rbrace$,
making $\Sigma\left[ n \right]$ a random string with a maximal length of n.
For the W-method the testing suite $T = S \concat \Sigma\left[ d + 1 \right]  \concat W$.
The idea behind the W-method is that $S \concat \Sigma\left[ 1 \right]  = S \cup S
\concat \Sigma$, which is also called the transition cover of $M$, ensures that all the
states and transition in $P$ are also present in $M$, while
$\Sigma\left[ n \right] \concat W$ ensures that $M$ and $P$ are in the same state after
performing all the transitions.

In order to use the W-method there are four requirements.
The machine must be minimal, completely specified, completely reachable, 
and have a fixed initial state.
With some additional manipulation these four assumptions may be violated.
The method consists of three steps:
\begin{enumerate}
\item estimation of the maximum number of states.
\item generation of test sequences.
\item verification of the responses.
\end{enumerate}

By exploiting domain specific knowledge, the W-method can be adapted to reduce
the number of test cases even further.
When dealing with a networked application for example, there are usually no
further possible transitions when a connection is closed by a remote machine.
Exploiting such knowledge can greatly reduce the number of tests necessary\cite{deRuiter2015}.

\subsection{Limiting the amount of membership queries}
In a theoretical framework the learning algorithm doesn't have to account
for execution times of individual \textit{MEMBER (w)} queries.
In practice, such queries might take time or be expensive to execute.
Therefore algorithms benefit from reducing the amount of queries needed.
Some generic improvements in this regard have already been covered in
\cref{sec:improvements}.

However, when using for example \textit{Chow's method} for \textit{EQUIV (M)}
queries, the amount of membership queries needed grows exponentially
in the number of states \cref{sec:chow}.

\todo{Cite ZULU participant here, since the challenge also imposed
      a maximum on \textit{MEMBER (w)} queries}

\subsection{Learning Mealy machines}
\label{sec:learn-mealy-mach}

The $L^*$ algorithm of Angluin is only able to learn DFA's (and equivalent
models). However, some applications are characterized by their I/O behaviour.
Such behaviour is not easily modeled by a DFA. Instead, they are more naturally
modeled by mealy machines\cite{Shahbaz2009} (see definition
\ref{def:mealy_machine}).

\begin{definition}[Mealy machine]\label{def:mealy_machine}
  A mealy machine $M$ is a 6-tuple $(Q, q_0, \Sigma, \Lambda, \delta, \lambda)$
  where $Q$ is the set of states, $q_0$ is the initial state, $\Sigma$ is the
  input alphabet, $\Lambda$ is the output alphabet, $\delta$ is the transition
  function and $\lambda$ is the output function.
\end{definition}

A mealy machine is similar to a DFA, but instead of defining accepting states,
it defines a function $\lambda: Q \times \Sigma \to \Lambda$ that defines
the output symbol returned on each state transition. To learn a mealy machine
with $L^*$, some adaptions are required: either the mealy machine can be
transformed into a DFA, or an adaptation of $L^*$ called $L^*_{M}$ can be used
to learn the mealy machine directly.

\subsubsection {Transforming a mealy machines into a DFA}

A mealy machine $\mathcal{M}$ can be transformed into a DFA $D$. By using the
alphabet of the transformed model, $D$ can be learned by the $L^*$ algorithm.
The only required change to the algorithm is the implementation of the
membership query, as will be explained below. There are two ways to transform
$\mathcal{M}$ into $D$. Both transformations have in common that they introduce
a single error state $q_{err}$, which is the only non-accepting state in $D$.
The main difference between the transformations is in the input alphabet they
define. One uses $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$\cite{Hungar2003},
while the other uses $\Sigma = \Sigma_\mathcal{M} \times O$ \cite{Makinen2001}.
Note that in this section the $_{\mathcal{M}}$ subscript is used to disambiguate
between items from the DFA and mealy tuples.


When using $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$, each transition in
$\mathcal{M}$ with input symbol $\sigma$ and output symbol $o$ is split into two
transitions. The first is constrained by $\sigma$ and transitions to a new
intermediate state $q_t$. The second transitions from $q_t$ and is constrained
by $o$. All inputs that are not defined after this step transition into
$q_{err}$. An example can be seen in figure \ref{fig:transformation_hungar} and
the pseudocode of this transformation is shown in algorithm
\ref{alg:transform_hungar}. The transformed model of $\mathcal{M}$ can be
learned by $L^*$ by defining $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$
\cite{Shahbaz2009} and using the appropriate $\mq$ and $\eq$ implementations
\cite{Hungar2003,Niese2003}.

\begin{algorithm}[h]
\caption{Transformation of a mealy machine into a DFA}
\label{alg:transform_hungar}
\begin{algorithmic}[1]
\Function{Transform}{$Q_\mathcal{M}, q_{0_\mathcal{M}}, \Sigma_\mathcal{M},
                     \Lambda, \delta_\mathcal{M}, \lambda$} 
  \State $Q \gets Q_\mathcal{M} \cup \{q_{err}\}$
  \State $q_0 \gets q_{0_\mathcal{M}}$
  \State $\Sigma \gets \Sigma_\mathcal{M} \cup \Lambda$
  \For{$(q,\sigma) \in Q_\mathcal{M} \times \Sigma_\mathcal{M}$}
  \Comment For each transition in $\mathcal{M}$
    \State add a new state $q_t$ to $Q$
    \State $\delta(q,\sigma) \gets q_t$
    \Comment Add a transition to $q_t$
    \State $\delta(q_t, \lambda(q,\sigma)) \gets \delta_\mathcal{M}(q, \sigma)$
    \Comment Add a transition from $q_t$
  \EndFor

  \For{$(q, \sigma) \in Q \times \Sigma$}
    \If{$\delta(q, \sigma)$ is not yet defined}
      \State $\delta(q, \sigma) \gets q_{err}$
    \EndIf
  \EndFor
  \State $F \gets Q - \{q_{err}\}$
  \State \Return $(Q, q_0, \Sigma, \delta, F)$
\EndFunction{}
\end{algorithmic}
\end{algorithm}

\begin{figure}[t]
\centering
\begin{subfigure}[b]{.4\textwidth}
\centering
\begin{tikzpicture}
  [bend angle=40,every node/.style={draw,circle}]

  \tikzstyle{initial} = [dashed]

  \node[initial]   (1) at (1,0) {};
  \node        (2) at (3,0) {};

  \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
        (1) edge [bend left] node[auto,draw=none] {$a/b$} (2) 
        (2) edge [bend left] node[auto,draw=none] {$a/b$} (1);
\end{tikzpicture}
\caption{Mealy representation} \label{fig:transformation_mealy}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}
  [bend angle=40,every node/.style={draw,circle}]

  \tikzstyle{initial} = [dashed]

  \node[initial, accepting] (1) at (1,0)  {};
  \node                     (2) at (3,0)  {};
  \node [accepting]         (3) at (5,0)  {};
  \node [accepting]         (4) at (3,-1) {};
  \node [accepting]         (5) at (3,1)  {};

  \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
      (1) edge [bend left] node[auto,draw=none] {$a$} (5) 
      (4) edge [bend left] node[auto,draw=none] {$b$} (1)
      (5) edge [bend left] node[auto,draw=none] {$b$} (3)
      (3) edge [bend left] node[auto,draw=none] {$a$} (4)
      (1) edge             node[auto,draw=none] {$b$} (2)
      (3) edge             node[auto,draw=none] {$b$} (2)
      (4) edge             node[auto,draw=none] {$a$} (2)
      (5) edge             node[auto,draw=none] {$a$} (2);
\end{tikzpicture}
\caption{Hungar's transformation} \label{fig:transformation_hungar}
\end{subfigure}

\caption{Mealy to DFA transformation} \label{fig:transformation}
\end{figure}

The second transformation uses $\Sigma = \Sigma_\mathcal{M} \times \Lambda$.
M\"{a}kinen~et~al were the first to use (a slightly modified version of) $L^*$
to learn a DFA with input/output pairs as input symbols. Several other papers
mention that a DFA with such inputs can be created from a Mealy machine by
taking $\Sigma = \Sigma_\mathcal{M} \times \Lambda$, and that there Mealy
machines can be learned by $L^*$ \cite{Shahbaz2009,Irfan2010,Groz2012}. This
transformation removes the need for intermediate states, but it has significant
impact on the size of the input alphabet \cite{Hungar2003}. Since none of the
mentioned papers explicitly define the transformation in detail, no pseudocode
is given here.

\subsubsection {Adapting $L^*$ into $L^*_{M}$}
Angluin's $L^*$ algorithm has been adjusted for use with mealy machines. The new
procedure was first informally described in \cite{Margaria2004}, and later more
rigorously in \cite{Shahbaz2009}. In $L^*$ the membership queries return a
boolean value; either it's a member, or it's not. For $L^*_{M}$, the membership
query is replaced by an output query, which returns an output string. The
observation table is modified to store these output strings instead of boolean
values. As in $L^*$, output queries are used in order to fill in the observation
table. Suppose the algorithm performs an output query for $s \concat e$, where
$s \in S \cup (S \concat \Sigma)$ and $e \in E$. The query will produce a string
$r$ with $|r| = |s| + |e|$, where $|x|$ denotes the length of the string $x$.
Instead of storing $r$ directly in the observation table, only the last $|e|$
symbols of $r$ are stored (since the observation is prefix closed, the output
corresponding to $s$ is already stored in the table). The intuitive meaning of
this value in the observation table is that it correspond to the sequence of
output symbols that is produced when the input $e$ is applied from the state
corresponding to $s$.

An example Mealy machine $\mathcal{M}$ is shown in figure
\ref{fig:mealy_example}. A possible observation table built by $L^*_M$ when it
learns $\mathcal{M}$ is shown in table \ref{tbl:mealy_observation_table} (source
of the example: Shahbaz~et~al \cite{Shahbaz2009}). In this table it can be seen
that the value in $\row(aa)$ under the column labeled by $a$ is $y$, even though
the output query would have returned the string $xyy$ for the input string
$aaa$.

With the new meaning of the values in the table, a value of $\epsilon$ in $E$
becomes nonsensical. This is because $\epsilon$ would denote no change in
state, so there would be no output symbol. Therefore, at the start of the
algorithm, $E$ is not intialized to $\{\epsilon\}$ but to $\Sigma$.

The concepts of closedness and consistency remain identical. The procedure to
build the hypothesis remains largely the same, but now the generated hypothesis
no longer defines accepting states, but instead defines outpusst strings on the
transitions. Following similar reasoning as in Angluin's paper
\cite{Angluin1987}, it can be concluded that $L^*_M$ is guaranteed to find a
model describing the target using at most $\mathcal{O}(k^2nm + kmn^2)$ output
queries \cite{Shahbaz2009}.

\begin{figure}[h]
  \begin{minipage}{.45\textwidth}
    \centering
    \begin{tikzpicture}
      [bend angle=40,every node/.style={draw,circle}]

      \tikzstyle{initial} = [dashed]

      \node[initial]   (1) at (1,0) {};
      \node        (2) at (3,0) {};

      \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
            (1) edge [bend left] node[auto,draw=none] {$a/x$} (2) 
            (2) edge [bend left] node[auto,draw=none] {$b/x$} (1)
            (1) edge [loop above] node[auto,draw=none] {$b/x$} (1)
            (2) edge [loop above] node[auto,draw=none] {$a/y$} (2);
    \end{tikzpicture}
    \captionof{figure}[t]{Example Mealy machine}
    \label{fig:mealy_example}
  \end{minipage}
%
  \begin{minipage}{.45\textwidth}
    \centering
    \begin{tabular}{ | l || c | c | }
      \hline
                  & $a$   & $b$ \\ \hline \hline
      $\epsilon$  & $x$   & $x$ \\ 
      $a$         & $y$   & $x$ \\ \hline \hline
      $b$         & $x$   & $x$ \\
      $aa$        & $y$   & $x$ \\
      $ab$        & $x$   & $x$ \\
      \hline
    \end{tabular}
    \captionof{table}[t]{Example observation table}
    \label{tbl:mealy_observation_table}
  \end{minipage}
\end{figure}


\subsection{Systems without a \textit{reset} function}
\label{sec:noreset}
In the L* learning algorithm, every \textit{MEMBER (w)} query is implicitly
independent of other queries.
However, when learning a system in practice, it might happen that
\textit{MEMBER (w)} queries are not independent at all.
Suppose for example that the system under learning requires authentication
while also imposing a restriction on the maximum amount of failed requests.
In such a system queries are no longer independent of each other,
since after a certain amount of authentication requests
the systems behaviour suddenly changes for the same membership queries.
In order to solve this issue, the L* algorithm implicitly requires a means
of \textit{reset}ting the system under learning (Rivest \& Schapire, pg. 301)\cite{Rivest1993}.

However, not all systems support a \textit{reset} function.
As we'll see in \cref{sec:applications}, the system under learning
could also be a system that the learning algorithm has totally no control over.
\todo{Explain homing sequences here}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
