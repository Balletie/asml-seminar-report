\section{Variants}
\label{sec:variants}
In the first few years following the introduction of the $L^*$ algorithm by
Angluin~\cite{Angluin1987}, $L^*$ learning was only a theoretical exploration.
The various improvements described in the previous section,
such as \textit{Classification Trees} \cref{sec:classification-trees} and
the \textit{TTT} algorithm \cref{sec:ttt} made practical applications more feasible.

The learning algorithms discussed in the previous sections all required an
(abstract, formal) input alphabet, an (abstract, formal) output alphabet,
membership queries and equivalence queries.
In practice, it is in many cases quite difficult to realize these requirements
for a specific system under learning (SUL)~\cite{Steffen2011a}.
This section discusses some of these challenges faced when
applying active state machine learning to real world scenarios, such as:
\begin{itemize}
  \item Equivalence queries are generally undecidable for black box systems.
  \item The amount of required membership queries can grow very fast,
        possibly making applications of $L^*$ learning very time consuming.
  \item $L^*$ can only interact with regular languages, not with real systems.
  \item $L^*$ assumes that the SUL can always return to its initial state,
        imposing the requirement that membership queries are independent.
        In practice the SUL might not be able to do so,
        which results in the requirement of a \textit{reset} function.
        However, not all systems support a \textit{reset} function.
\end{itemize}
For each of these challenges a variant of the $L^*$ algorithm will be discussed
that addresses the specific issues encountered.

\subsection{Approximating Equivalence Queries with Membership Queries}
In theoretical simulations, equivalence testing is often easy because the target
system (in some cases even the model!) is known. In practice, however, the SUL
is generally a black box, since the main motive for using a learning algorithm
is to infer knowledge about some unknown system. Therefore equivalence queries
can generally only be answered by exhaustively testing the inputs and outputs of
a system. However, exhaustively testing a black box is undecidably hard.

This means that equivalence queries will have to be approximated, typically by
using membership queries. Together with the introduction of the $L^*$ algorithm,
Angluin introduced a way to approximate the equivalence queries by executing a
series of membership queries~\cite{Angluin1987}. For each of these membership
queries, a random sequence from $\Sigma^*$ is generated and is then checked
against both the hypothesis and the target. This process is repeated until
either a counterexample has been found or the desired confidence that the
hypothesis is correct is reached. This confidence is a configurable parameter.
Its value depends on the desired probability that a correct model of the target
is learned. This approach does not guarantee a correct result of the equivalence
query. Despite this, it is still used in practice either exclusively (e.g.~\cite{Cho2010}) or in combination with more robust alternatives such as Chow's
W-method (e.g.~\cite{Bauer2014}).
\todo{cite reason why random sampling is still used}

\subsubsection{Chow's W-method}
\label{sec:chow}

Chow's W-method is a form of model-based testing~\cite{deRuiter2015, Chow1978}.
Like Angluin's random sampling technique, it uses membership queries to
approximate equivalence queries. The advantage of this method is that it is able
to guarantee the correct result of equivalence queries, given an upper bound of
the number of states in the target~\cite{Ipate2007}.

According to~\cite{Vasilevskii1973}, the maximum number of test sequences needed
to converge to a correct approximation of the SUL is bounded by $n^{2} \times
k^{m-n+1}$ when using Chow's W-method. The maximum length of these sequences is
$n^{2} \times m \times k^{m-n+1}$, where $n$ is the number of states in the
provided automaton, $m$ is the number of states in the correct automaton and $k$
is the size of the input alphabet.

By refining the test suites and the specification at the same time
and by using a divide and conquer approach, the size of the test is
considerably reduced in comparison to defining the tests from
the final specification~\cite{Ipate2007, Chow1978}.
This is especially beneficial because complex systems are usually
created in multiple iterations.
Unlike some other test selection methods the W-method does not require
that the number of states is exactly the same between
the implementation and protocol.
The W-method generates tests that guarantee correctness of an
implementation with a number of states below a certain upper bound.

The W-method generates input sequences that reach every state in the
diagram, checks all the transitions in the diagram and identifies all the
destination states and verifies them against their counterparts in
the implementation~\cite{Ipate2007}.
To achieve this, the W-method constructs two sets of input sequences:
\begin{itemize}
  \item A state cover $S \subseteq \Sigma^{*}$ that reaches every state in the
    final state machine, including the empty sequence to reach the initial state.
  \item A characterization set $W \subseteq \Sigma^{*}$ that has different
    outputs for at least one sequence in $W$ for every pair of different states.
\end{itemize}

Given a specification $P$ that can be modeled by an unknown finite state machine $M$,
the only information the algorithm needs is an estimate of the maximum number of
states of an unknown model for the specification.
Suppose $d$ is the difference between the estimated maximum number of states in $P$
and the number of states in the machine $M$.
Also take $\Sigma \left[ n \right] = \Sigma^{n} \cup \dots \cup \lbrace \epsilon \rbrace$,
making $\Sigma\left[ n \right]$ a random string with a maximal length of $n$.
For the W-method the testing suite $T = S \concat \Sigma\left[ d + 1 \right]  \concat W$.
The idea behind the W-method is that $S \concat \Sigma\left[ 1 \right]  = S \cup (S
\concat \Sigma)$, which is also called the transition cover of $M$, ensures that all the
states and transition in $P$ are also present in $M$, while
$\Sigma\left[ n \right] \concat W$ ensures that $M$ and $P$ are in the same state after
performing all the transitions. For pseudocode see algorithm~\ref{alg:w-method}.

\begin{algorithm}[h]
\caption{The W-method algorithm}
\label{alg:w-method}
\begin{algorithmic}[1]
\Function{W-method}{$P, M, \Sigma, Reset$} \Comment{$P$ is the protocol (or Teacher) to test against, $M$ is the machine to test,
$\Sigma$ is the input alphabet of $M$ and $Reset$ is the reset function}
\State $S \gets \{ \epsilon \}$ \Comment{Initialize state cover set}
\State $W \gets \{ \epsilon \}$ \Comment{Initialize characterization set}
\State $X \gets \emptyset$ \Comment{Initialize an emty set for words of a maximum length}

%\For{State $q \in M$}
%\State $S$.add(q.accessString) \Comment{Build state cover S}
%\EndFor
\State Build $S$ \Comment{Build state cover}
\State Build $W$ \Comment{Build the characterization set}
\ForAll{$0 \leq i \leq (estimatedstates(P) - numstates(M) + 1)$} \Comment{Build the set of words with the given
maximum length}
\State $X \gets X \cup \Sigma^{i}$ \Comment{Add word of length $i$}
\EndFor

\For{$s \in S$}
\For{$w \in W$}
\For{$a \in X$}
\If{$P$ accepts $(s \concat a \concat w) \neq $ $M$ accepts $(s \concat a \concat w)$}
\Comment{Check equality for $s \concat a \concat w$}
\State \Return "not equal"
\EndIf
\State \Call{Reset}{$P, M$} \Comment{Reset $P$ and $M$}
\EndFor
\EndFor
\EndFor

\State \Return "equal"

\EndFunction{}
\end{algorithmic}
\end{algorithm}

\subsection{Limiting the Amount of Membership Queries}
Membership queries are the most straightforward to translate to real world
applications: they can be realized via testing.  An important thing to note,
however, is the amount of membership queries required.  In a theoretical
framework the learning algorithm does not have to account for execution times of
individual membership queries. In practice, such queries might take
considerable time or be expensive to execute.

Learning a real world application can easily require several thousand membership
queries~\cite[p. 100]{Tomte2014}. Furthermore, when using for example
\textit{Chow's method} for equivalence queries, the amount of membership queries
needed grows exponentially in the number of states~\cite{Chow1978}.  This means
that the time required to learn a model can be greatly reduced either by
speeding up membership queries (executing them in parallel~\cite{Howar2012}), or
simply by reducing the number of membership queries required (\cref{sec:tools}).

\Cref{sec:improvements} has discussed several improvements to achieve exactly
that. Additionally, domain-specific optimizations can be used to further reduce
the number of membership queries required significantly.  When dealing with a
network protocol such as TLS~\cite{deRuiter2015} \todo{reference TLS section}
for example, after a network connection is closed, there are usually no further
possible transitions for the protocol state.  Accounting for this behavior in
the implementation of the W-method resulted in a decrease from 68578 to 4126
equivalence queries.

Another initiative to decrease the number of membership queries required
to efficiently learn a system was the ZULU Challenge~\cite{Howar2010b}
The ZULU challenge aimed to represent a realistic learning scenario,
which meant the learning algorithm could ask only a limited amount of
membership queries and no equivalence queries at all.
This effectively rules out any use of the W-method.
According to Howar~et~al. this meant a shift in objective from
"Trying to prove equivalence" to "Finding counterexamples fast".

They won using a slightly modified Observation Pack algorithm (\cref{sec:ttt}):
instead of building a new hypothesis automaton each iteration as done
in the $L^*$ algorithm, their modified algorithm progressively refined
the hypothesis to avoid rebuilding from scratch,
eventually converging to a correct model.
Their algorithm combined heuristics for finding
counterexamples~\cite{Howar2010b} with Rivest \& Schapire-style counterexample
analysis~(\cref{sec:rivest-schap-count}) to implement a global continuous
equivalence querying process.
Using this approach, Howar~et~al. found the most complete
model of the SUL using a limited amount of membership queries.

\subsection{Learning Mealy Machines}
\label{sec:learn-mealy-mach}

By modifying the $L^*$ algorithm and using model transformation techniques, many
different automaton types can be learned, including Mealy machines~\cite{Shahbaz2009}, I/O automata~\cite{Aarts2010a}, register automata~\cite{Howar2012} and event-recording automata~\cite{Grinchtein05}. In this
article only the Mealy variant is discussed in detail.

The basic $L^*$ algorithm is only able to learn DFAs (and equivalent
models). However, some applications are characterized by their input/output behavior.
Such behavior is not easily modeled by a DFA. Instead, they are more naturally
modeled by Mealy machines~\cite{Shahbaz2009} (see definition~\ref{def:mealy_machine}).

\begin{definition}[Mealy machine]\label{def:mealy_machine}
  A Mealy machine $M$ is a 6-tuple $(Q, q_0, \Sigma, \Lambda, \delta, \lambda)$
  where $Q$ is the set of states, $q_0$ is the initial state, $\Sigma$ is the
  input alphabet, $\Lambda$ is the output alphabet, $\delta$ is the transition
  function and $\lambda$ is the output function.
\end{definition}

A Mealy machine is similar to a DFA, but instead of defining accepting states,
it defines a function $\lambda: Q \times \Sigma \to \Lambda$ that defines
the output symbol returned on each state transition. To learn a Mealy machine
with $L^*$, some adaptions are required: either the Mealy machine can be
transformed into a DFA, or an adaptation of $L^*$ called $L^*_{M}$ can be used
to learn the Mealy machine directly.

\subsubsection {Transforming a Mealy machine into a DFA}

A Mealy machine $\mathcal{M}$ can be transformed into a DFA $D$. By using the
alphabet of the transformed model, $D$ can be learned by the $L^*$ algorithm.
The only required change to the algorithm is the implementation of the
membership query, as will be explained below. There are two ways to transform
$\mathcal{M}$ into $D$. Both transformations have in common that they introduce
a single error state $q_{err}$, which is the only non-accepting state in $D$.
The main difference between the transformations is in the input alphabet they
define. One uses $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$~\cite{Hungar2003},
while the other uses $\Sigma = \Sigma_\mathcal{M} \times O$~\cite{Makinen2001}.
Note that in this section the $_{\mathcal{M}}$ subscript is used to disambiguate
between items from the DFA and Mealy tuples.


When using $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$, each transition in
$\mathcal{M}$ with input symbol $\sigma$ and output symbol $o$ is split into two
transitions. The first is constrained by $\sigma$ and transitions to a new
intermediate state $q_t$. The second transitions from $q_t$ and is constrained
by $o$. All inputs that are not defined after this step transition into
$q_{err}$. An example can be seen in figure~\ref{fig:transformation_hungar} and
the pseudocode of this transformation is shown in algorithm~\ref{alg:transform_hungar}. The transformed model of $\mathcal{M}$ can be
learned by $L^*$ by defining $\Sigma = \Sigma_\mathcal{M} \cup \Lambda$~\cite{Shahbaz2009} and using the appropriate $\mq$ and $\eq$ implementations~\cite{Hungar2003,Niese2003}.

\begin{algorithm}[h]
\caption{Transformation of a Mealy machine into a DFA}
\label{alg:transform_hungar}
\begin{algorithmic}[1]
\Function{Transform}{$Q_\mathcal{M}, q_{0_\mathcal{M}}, \Sigma_\mathcal{M},
                     \Lambda, \delta_\mathcal{M}, \lambda$}
  \State $Q \gets Q_\mathcal{M} \cup \{q_{err}\}$
  \State $q_0 \gets q_{0_\mathcal{M}}$
  \State $\Sigma \gets \Sigma_\mathcal{M} \cup \Lambda$
  \For{$(q,\sigma) \in Q_\mathcal{M} \times \Sigma_\mathcal{M}$}
  \Comment For each transition in $\mathcal{M}$
    \State add a new state $q_t$ to $Q$
    \State $\delta(q,\sigma) \gets q_t$
    \Comment Add a transition to $q_t$
    \State $\delta(q_t, \lambda(q,\sigma)) \gets \delta_\mathcal{M}(q, \sigma)$
    \Comment Add a transition from $q_t$
  \EndFor

  \For{$(q, \sigma) \in Q \times \Sigma$}
    \If{$\delta(q, \sigma)$ is not yet defined}
      \State $\delta(q, \sigma) \gets q_{err}$
    \EndIf
  \EndFor
  \State $F \gets Q - \{q_{err}\}$
  \State \Return $(Q, q_0, \Sigma, \delta, F)$
\EndFunction{}
\end{algorithmic}
\end{algorithm}

\begin{figure}[t]
\centering
\begin{subfigure}[b]{.4\textwidth}
\centering
\begin{tikzpicture}
  [bend angle=40,every node/.style={draw,circle}]

  \tikzstyle{initial} = [dashed]

  \node[initial]   (1) at (1,0) {};
  \node        (2) at (3,0) {};

  \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
        (1) edge [bend left] node[auto,draw=none] {$a/b$} (2)
        (2) edge [bend left] node[auto,draw=none] {$a/b$} (1);
\end{tikzpicture}
\caption{Mealy representation} \label{fig:transformation_mealy}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tikzpicture}
  [bend angle=40,every node/.style={draw,circle}]

  \tikzstyle{initial} = [dashed]

  \node[initial, accepting] (1) at (1,0)  {};
  \node                     (2) at (3,0)  {};
  \node [accepting]         (3) at (5,0)  {};
  \node [accepting]         (4) at (3,-1) {};
  \node [accepting]         (5) at (3,1)  {};

  \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
        (1) edge [bend left] node[auto,draw=none] {$a$} (5)
        (4) edge [bend left] node[auto,draw=none] {$b$} (1)
        (5) edge [bend left] node[auto,draw=none] {$b$} (3)
        (3) edge [bend left] node[auto,draw=none] {$a$} (4)
        (1) edge 			 node[auto,draw=none] {$b$} (2)
        (3) edge 			 node[auto,draw=none] {$b$} (2)
        (4) edge 			 node[auto,draw=none] {$a$} (2)
        (5) edge 			 node[auto,draw=none] {$a$} (2);
\end{tikzpicture}
\caption{Hungar's transformation} \label{fig:transformation_hungar}
\end{subfigure}

\caption{Mealy to DFA transformation} \label{fig:transformation}
\end{figure}

The second transformation uses $\Sigma = \Sigma_\mathcal{M} \times \Lambda$.
M\"{a}kinen~et~al. were the first to use (a slightly modified version of) $L^*$
to learn a DFA with input/output pairs as input symbols. Several other papers
mention that a DFA with such inputs can be created from a Mealy machine by
taking $\Sigma = \Sigma_\mathcal{M} \times \Lambda$ and that therefore Mealy
machines can be learned by $L^*$~\cite{Shahbaz2009,Irfan2010,Groz2012}. This
transformation removes the need for intermediate states, but it has
significant impact on the size of the input alphabet~\cite{Hungar2003}. Since
no papers could be found that explicitly define the transformation in detail,
no pseudocode is given here.

\subsubsection {Adapting $L^*$ into $L^*_{M}$}
Angluin's $L^*$ algorithm has been adjusted for use with Mealy machines. The new
procedure was first informally described in~\cite{Margaria2004} and later more
rigorously in~\cite{Shahbaz2009}. In $L^*$ the membership queries return a
boolean value; either it is a member, or it is not. For $L^*_{M}$, the membership
query is replaced by an output query, which returns an output string. The
observation table is modified to store these output strings instead of boolean
values. As in $L^*$, output queries are used in order to fill in the observation
table. Suppose the algorithm performs an output query for $s \concat e$, where
$s \in S \cup (S \concat \Sigma)$ and $e \in E$. The query will produce a string
$r$ with $|r| = |s| + |e|$, where $|x|$ denotes the length of the string $x$.
Instead of storing $r$ directly in the observation table, only the last $|e|$
symbols of $r$ are stored (since the observation is prefix closed, the output
corresponding to $s$ is already stored in the table). The intuitive meaning of
this value in the observation table is that it corresponds to the sequence of
output symbols that is produced when the input $e$ is applied from the state
corresponding to $s$.

An example Mealy machine $\mathcal{M}$ is shown in figure~\ref{fig:mealy_example}. A possible observation table built by $L^*_M$ when it
learns $\mathcal{M}$ is shown in table~\ref{tbl:mealy_observation_table} (source
of the example: Shahbaz~et~al.~\cite{Shahbaz2009}). In this table it can be seen
that the value in $\row(aa)$ under the column labeled by $a$ is $y$, even though
the output query would have returned the string $xyy$ for the input string
$aaa$.

With the new meaning of the values in the table, a value of $\epsilon$ in $E$
becomes nonsensical. This is because $\epsilon$ would denote no change in
state, so there would be no output symbol. Therefore, at the start of the
algorithm, $E$ is not intialized to $\{\epsilon\}$ but to $\Sigma$.

The concepts of closedness and consistency remain identical. The procedure to
build the hypothesis remains largely the same, but now the generated hypothesis
no longer defines accepting states. Instead, it defines output strings on the
transitions. Following similar reasoning as in Angluin's paper~\cite{Angluin1987}, it can be concluded that $L^*_M$ is guaranteed to find a
model describing the target using at most $\mathcal{O}(k^2nm + kmn^2)$ output
queries~\cite{Shahbaz2009}.

\begin{figure}[h]
  \begin{minipage}{.45\textwidth}
    \centering
    \begin{tikzpicture}
      [bend angle=40,every node/.style={draw,circle}]

      \tikzstyle{initial} = [dashed]

      \node[initial]   (1) at (1,0) {};
      \node        (2) at (3,0) {};

      \path[->, >=stealth, shorten > = 1pt, shorten < = 1pt]
            (1) edge [bend left] node[auto,draw=none] {$a/x$} (2)
            (2) edge [bend left] node[auto,draw=none] {$b/x$} (1)
            (1) edge [loop above] node[auto,draw=none] {$b/x$} (1)
            (2) edge [loop above] node[auto,draw=none] {$a/y$} (2);
    \end{tikzpicture}
    \captionof{figure}[t]{Example Mealy machine}
    \label{fig:mealy_example}
  \end{minipage}
%
  \begin{minipage}{.45\textwidth}
    \centering
    \begin{tabular}{ | l || c | c | }
      \hline
                  & $a$   & $b$ \\ \hline \hline
      $\epsilon$  & $x$   & $x$ \\
      $a$         & $y$   & $x$ \\ \hline \hline
      $b$         & $x$   & $x$ \\
      $aa$        & $y$   & $x$ \\
      $ab$        & $x$   & $x$ \\
      \hline
    \end{tabular}
    \captionof{table}[t]{Example observation table}
    \label{tbl:mealy_observation_table}
  \end{minipage}
\end{figure}


\subsection{Systems Without a \textit{Reset} Function}
\label{sec:noreset}
In the $L^*$ learning algorithm, every membership query is implicitly
independent of other queries. However, when learning a system in practice, it
might happen that membership queries are not independent at all. Suppose for
example that the SUL requires authentication while also imposing a restriction
on the maximum amount of failed requests. In such a system queries are no longer
independent of each other, since after a certain amount of authentication
requests the behavior of the system suddenly changes for the same membership
queries. In order to solve this issue, the $L^*$ algorithm implicitly requires a
means of resetting the SUL~\cite[p. 301]{Rivest1993} in between successive
membership queries.

However, not in all situations a reset function is desirable. An example is a
system where the reset takes a lot of time compared to the learning process. For
such systems a reduction in the amount of resets is helpful. The method proposed
by Bauer~et~al.~\cite{Bauer2012} can be used for this situation. This method
reuses already (or partially) asked membership queries by only sending the
remaining part of the query to the Teacher. It then combines the answer of the
Teacher (if needed) with the answer of previously asked queries, which is sent
back to the learning algorithm. The system then only needs to reset if the
complete membership query has not already been asked before. Other systems lack
any support for a reset function. As will be seen in \cref{sec:applications},
the SUL could well be a system over which the algorithm has no control.

%Section 3.5?
%Another obstacle to overcome is that of parameters used in real world
%applications. Think, for example, about increasing sequence numbers in
%communication protocols. This is still a huge challenge to
%resolve~\cite{Steffen2011a} and for now, besides the creation of prototypical
%solutions~\cite{Aarts2010,Shahbaz2007,Howar2010},
%application-specific solutions have to be applied~\cite{Steffen2011a}.

\subsubsection{Homing sequences}
In 1993 Rivest \& Schapire proposed an extension to $L^*$~\cite[p. 312]{Rivest1993}
that replaces the implicitly required reset by homing sequences.
A homing sequence is an input string for which the automaton is guaranteed to
produce a sequence of outputs that completely determines the final reached state.
The sequence of outputs on input $w$ starting from a state $q$ is denoted as
$q \langle w \rangle$.
Now suppose $M$ is a DFA. A homing sequence $h$ for $M$ with outputs $s$ is then
a sequence of strings, such that $(\forall{q_1 \in Q})(\forall{q_2 \in Q})
(q_1 \langle h \rangle = q_2 \langle h \rangle = s)$.

This also implies that every distinguisting sequence is a homing sequence,
since for all states $q_1$ and $q_2$ and a distinguishing extension $a$,
it can be deduced that $\delta(q_1, a) = \delta(q_2, a) \Rightarrow q_1 = q_2$
and therefore $q_1 \langle a \rangle = q_2 \langle a \rangle$.

Given this definition of a homing sequence, together with the prerequisite
that some state with outputs $s$ can be reached regularly by executing $h$,
it can immediately be seen how a homing sequence can be used to simulate a reset:
\begin{algorithm}[hb]
  \caption{Simulate a reset of the system with a homing sequence.}
  \label{alg:reset-homing}
  \begin{algorithmic}[1]
    \Function{Reset}{$M,h,s$} \Comment{With $M$ a DFA, $h$ a homing sequence and $s$ a sequence of outputs}
      \Do
        \State $o \gets $ result of executing $h$ on $M$
      \doWhile{$o \neq s$}
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

From the definition, given a homing sequence $h$, the state that is reached
by executing $h$ can be identified by a sequence of outputs $s$.
Therefore the algorithm can just execute $h$ for as long as its sequence of
outputs differs $o$ from $s$ and eventually the state identified by $s$ will be reached.
The $L^*$ algorithm can now just substitute its initial state with the state
reached eventually by executing $h$, giving it the ability to simulate a reset.

With every string there is the possibility that $M$ gets trapped in a loop.
Therefore it is generally quite hard if not impossible to find such a state.
Rivest \& Schapire solve this by simulating independent copies of $M$ for each
possible output $s$ on executing $h$~\cite[p. 313]{Rivest1993}.  Since the set
of possible outputs on $h$ is limited by the number of states $n$, the amount of
independent copies is bounded by $\mathcal{O}(n)$.  Therefore this algorithm is
bounded by $\mathcal{O}(n \cdot (m + e))$, with $m$ the amount of membership
queries and $e$ the amount of equivalence queries.
\\
\\
All the above problems might give the impression that active state machine
learning is not yet applicable to real world applications. While it is true that
practical application is not yet complete, great progress has been made and
great things have already been achieved. The last section serves to highlight
some real world applications that illustrates these facts.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
